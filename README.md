ðŸŽ¬ IMDB Sentiment Classifier

Trains Logistic Regression and Multinomial Naive Bayes models on IMDB movie reviews to classify sentiments as positive or negative.
Performs text cleaning, TF-IDF vectorization, model training, and evaluation with both console output and a saved report.

â¸»

ðŸ“š Overview

This script performs binary sentiment classification using two classic NLP models:
	â€¢	Logistic Regression â€” strong linear baseline for text classification
	â€¢	Multinomial Naive Bayes â€” fast probabilistic model well-suited for word frequency features

It demonstrates how text preprocessing, TF-IDF feature extraction, and model evaluation can be integrated into a reproducible and documented workflow.

â¸»

âš™ï¸ Requirements

pip install pandas numpy scikit-learn


â¸»

ðŸ§  Features
	â€¢	âœ… Text cleaning (HTML & punctuation removal)
	â€¢	âœ… TF-IDF vectorization (20k features, unigrams + bigrams)
	â€¢	âœ… Trains Logistic Regression and MultinomialNB models
	â€¢	âœ… Evaluates models with accuracy, precision, recall, F1, and confusion matrix
	â€¢	âœ… Prints random sample reviews with sentiment emojis
	â€¢	âœ… Saves evaluation results to a text report (reports/evaluation.txt)

â¸»

ðŸ—‚ï¸ Project Structure

.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ IMDB Dataset.csv
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ evaluation.txt
â””â”€â”€ imdb_sentiment_classifier.py


â¸»

ðŸš€ Usage
	1.	Download the IMDB dataset â†’ data/IMDB Dataset.csv
	2.	Run the script:

python imdb_sentiment_classifier.py


	3.	After running:
	â€¢	The script will print random reviews with their predicted sentiment
	â€¢	Evaluation results for both models will be saved under
reports/evaluation.txt

â¸»

ðŸ“Š Example Output

ðŸ˜Š Positive -> Loved the performances!
ðŸ˜  Negative -> The movie dragged forever...

=== Logistic Regression ===
Accuracy: 0.8842

Classification Report:
              precision    recall  f1-score   support
0             0.88        0.89      0.88      12500
1             0.89        0.88      0.88      12500

Confusion Matrix:
[[11100 1400]
 [1550 10950]]

=== Multinomial Naive Bayes ===
Accuracy: 0.8715

Classification Report:
              precision    recall  f1-score   support
0             0.87        0.87      0.87      12500
1             0.87        0.87      0.87      12500

Confusion Matrix:
[[10875 1625]
 [1610 10890]]


â¸»

ðŸ§© Next Steps
	â€¢	Add cross-validation and hyperparameter tuning
	â€¢	Automate model comparison with saved summaries
	â€¢	Extend evaluation metrics (ROC-AUC, precision-recall curve)
	â€¢	Explore alternative models (SVM, RandomForest, or deep learning approaches)
